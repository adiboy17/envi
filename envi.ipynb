{"cells":[{"metadata":{},"cell_type":"markdown","source":"# VIS Tutorial \n\nWhen starting an image-based phenotyping project it is important to consider what the end goals of the project are.\nThe goals of the project will determine the the camera type, imaging layout, and will help to \nguide downstream analysis. For example, if the goal of the project is to quantify the growth rates of a population of \nArabidopsis plants, you may want to take timelapse images of whole flats of plants with an RGB (VIS) camera.\n\nTo run a VIS workflow over a single VIS image there are two required inputs:\n\n1.  **Image:** Images can be processed regardless of what type of VIS camera was used (high-throughput platform, digital camera, cell phone camera).\nImage processing will work with adjustments if images are well lit and free of background that is similar in color to plant material.  \n2.  **Output directory:** If debug mode is set to 'print' output images from each step are produced."},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# Import Libraries \nfrom plantcv import plantcv as pcv\nimport matplotlib\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"class options:\n    def __init__(self):\n        self.image = \"img/tutorial_images/vis/original_image.jpg\"\n        self.debug = \"plot\"\n        self.writeimg= False\n        self.result = \"./vis_tutorial_results\"\n        self.outdir = \".\" # Store the output to the current directory\n        \n# Get options\nargs = options()\n\n# Set debug to the global parameter \npcv.params.debug = args.debug\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Read image\n\n# Inputs:\n#   filename - Image file to be read in \n#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\nimg, path, filename = pcv.readimage(filename=args.image)\n","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# Convert RGB to HSV and extract the saturation channel\n\n# Inputs:\n#   rgb_image - RGB image data \n#   channel - Split by 'h' (hue), 's' (saturation), or 'v' (value) channel\ns = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Take a binary threshold to separate plant from background. \n# Threshold can be on either light or dark objects in the image. \n\n# Inputs:\n#   gray_img - Grayscale image data \n#   threshold- Threshold value (between 0-255)\n#   max_value - Value to apply above threshold (255 = white) \n#   object_type - 'light' (default) or 'dark'. If the object is lighter than \n#                 the background then standard threshold is done. If the object \n#                 is darker than the background then inverse thresholding is done. \ns_thresh = pcv.threshold.binary(gray_img=s, threshold=85, max_value=255, object_type='light')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Median Blur to clean noise \n\n# Inputs: \n#   gray_img - Grayscale image data \n#   ksize - Kernel size (integer or tuple), (ksize, ksize) box if integer input,\n#           (n, m) box if tuple input \ns_mblur = pcv.median_blur(gray_img=s_thresh, ksize=5)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# An alternative to using median_blur is gaussian_blur, which applies \n# a gaussian blur filter to the image. Depending on the image, one \n# technique may be more effective than others. \n\n# Inputs:\n#   img - RGB or grayscale image data\n#   ksize - Tuple of kernel size\n#   sigma_x - Standard deviation in X direction; if 0 (default), \n#            calculated from kernel size\n#   sigma_y - Standard deviation in Y direction; if sigmaY is \n#            None (default), sigmaY is taken to equal sigmaX\ngaussian_img = pcv.gaussian_blur(img=s_thresh, ksize=(5, 5), sigma_x=0, sigma_y=None)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using multiple colorspace channels can lead to better descrimination between plant and the background in an image. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert RGB to LAB and extract the blue channel ('b')\n\n# Input:\n#   rgb_img - RGB image data \n#   channel- Split by 'l' (lightness), 'a' (green-magenta), or 'b' (blue-yellow) channel\nb = pcv.rgb2gray_lab(rgb_img=img, channel='b')\n\n# Threshold the blue channel image \nb_thresh = pcv.threshold.binary(gray_img=b, threshold=160, max_value=255, \n                                object_type='light')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Join the threshold saturation and blue-yellow images with a logical or operation \n\n# Inputs: \n#   bin_img1 - Binary image data to be compared to bin_img2\n#   bin_img2 - Binary image data to be compared to bin_img1\nbs = pcv.logical_or(bin_img1=s_mblur, bin_img2=b_thresh)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Appy Mask (for VIS images, mask_color='white')\n\n# Inputs:\n#   img - RGB or grayscale image data \n#   mask - Binary mask image data \n#   mask_color - 'white' or 'black' \nmasked = pcv.apply_mask(img=img, mask=bs, mask_color='white')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we'll focus on capturing the plant in the masked image. We will use masked green-magenta and blue-yellow channels. \nThen two channels are thresholded to caputre different portions of the plant, and thre three images are joined together. \nSmall objected are filled, and the resulting binary image is used to mask the masked image previously obtained. "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert RGB to LAB and extract the Green-Magenta and Blue-Yellow channels\n\nmasked_a = pcv.rgb2gray_lab(rgb_img=masked, channel='a')\nmasked_b = pcv.rgb2gray_lab(rgb_img=masked, channel='b')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Threshold the green-magenta and blue images\n\nmaskeda_thresh = pcv.threshold.binary(gray_img=masked_a, threshold=115, \n                                      max_value=255, object_type='dark')\nmaskeda_thresh1 = pcv.threshold.binary(gray_img=masked_a, threshold=135, \n                                       max_value=255, object_type='light')\nmaskedb_thresh = pcv.threshold.binary(gray_img=masked_b, threshold=128, \n                                      max_value=255, object_type='light')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Join the thresholded saturation and blue-yellow images (OR)\n\nab1 = pcv.logical_or(bin_img1=maskeda_thresh, bin_img2=maskedb_thresh)\nab = pcv.logical_or(bin_img1=maskeda_thresh1, bin_img2=ab1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Opening filters out bright noise from an image.\n\n# Inputs:\n#   gray_img - Grayscale or binary image data\n#   kernel - Optional neighborhood, expressed as an array of 1's and 0's. If None (default),\n#   uses cross-shaped structuring element.\nopened_ab = pcv.opening(gray_img=ab)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Depending on the situation it might be useful to use the \n# exclusive or (pcv.logical_xor) function. \n\n# Inputs: \n#   bin_img1 - Binary image data to be compared to bin_img2\n#   bin_img2 - Binary image data to be compared to bin_img1\nxor_img = pcv.logical_xor(bin_img1=maskeda_thresh, bin_img2=maskedb_thresh)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Fill small objects (reduce image noise) \n\n# Inputs: \n#   bin_img - Binary image data \n#   size - Minimum object area size in pixels (must be an integer), and smaller objects will be filled\nab_fill = pcv.fill(bin_img=ab, size=200)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Closing filters out dark noise from an image.\n\n# Inputs:\n#   gray_img - Grayscale or binary image data\n#   kernel - Optional neighborhood, expressed as an array of 1's and 0's. If None (default),\n#   uses cross-shaped structuring element.\nclosed_ab = pcv.closing(gray_img=ab_fill)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Apply mask (for VIS images, mask_color=white)\nmasked2 = pcv.apply_mask(img=masked, mask=ab_fill, mask_color='white')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we need to identify the objects (also called contours) within the image "},{"metadata":{"trusted":false},"cell_type":"code","source":"# Identify objects\n\n# Inputs: \n#   img - RGB or grayscale image data for plotting \n#   mask - Binary mask used for detecting contours \nid_objects, obj_hierarchy = pcv.find_objects(img=masked2, mask=ab_fill)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Define the region of interest (ROI) \n\n# Inputs: \n#   img - RGB or grayscale image to plot the ROI on \n#   x - The x-coordinate of the upper left corner of the rectangle \n#   y - The y-coordinate of the upper left corner of the rectangle \n#   h - The height of the rectangle \n#   w - The width of the rectangle \nroi1, roi_hierarchy= pcv.roi.rectangle(img=masked2, x=100, y=100, h=200, w=200)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Decide which objects to keep\n\n# Inputs:\n#    img            = img to display kept objects\n#    roi_contour    = contour of roi, output from any ROI function\n#    roi_hierarchy  = contour of roi, output from any ROI function\n#    object_contour = contours of objects, output from pcv.find_objects function\n#    obj_hierarchy  = hierarchy of objects, output from pcv.find_objects function\n#    roi_type       = 'partial' (default, for partially inside the ROI), 'cutto', or \n#                     'largest' (keep only largest contour)\nroi_objects, hierarchy3, kept_mask, obj_area = pcv.roi_objects(img=img, roi_contour=roi1, \n                                                               roi_hierarchy=roi_hierarchy, \n                                                               object_contour=id_objects, \n                                                               obj_hierarchy=obj_hierarchy,\n                                                               roi_type='partial')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Object combine kept objects\n\n# Inputs:\n#   img - RGB or grayscale image data for plotting \n#   contours - Contour list \n#   hierarchy - Contour hierarchy array \nobj, mask = pcv.object_composition(img=img, contours=roi_objects, hierarchy=hierarchy3)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The next step is to analyze the plant object for traits such as horizontal height, shape, or color."},{"metadata":{"trusted":false},"cell_type":"code","source":"############### Analysis ################ \n  \n# Find shape properties, data gets stored to an Outputs class automatically\n\n# Inputs:\n#   img - RGB or grayscale image data \n#   obj- Single or grouped contour object\n#   mask - Binary image mask to use as mask for moments analysis \nanalysis_image = pcv.analyze_object(img=img, obj=obj, mask=mask)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Shape properties relative to user boundary line (optional)\n\n# Inputs:\n#   img - RGB or grayscale image data \n#   obj - Single or grouped contour object \n#   mask - Binary mask of selected contours \n#   line_position - Position of boundary line (a value of 0 would draw a line \n#                   through the bottom of the image) \nboundary_image2 = pcv.analyze_bound_horizontal(img=img, obj=obj, mask=mask, \n                                               line_position=370)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Determine color properties: Histograms, Color Slices and Pseudocolored Images, output color analyzed images (optional)\n\n# Inputs:\n#   rgb_img - RGB image data\n#   mask - Binary mask of selected contours \n#   hist_plot_type - None (default), 'all', 'rgb', 'lab', or 'hsv'\n#                    This is the data to be printed to the SVG histogram file  \ncolor_histogram = pcv.analyze_color(rgb_img=img, mask=kept_mask, hist_plot_type='all')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Print the histogram out to save it \npcv.print_image(img=color_histogram, filename=\"vis_tutorial_color_hist.jpg\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Divide plant object into twenty equidistant bins and assign pseudolandmark points based upon their \n# actual (not scaled) position. Once this data is scaled this approach may provide some information \n# regarding shape independent of size.\n\n# Inputs:\n#   img - RGB or grayscale image data \n#   obj - Single or grouped contour object \n#   mask - Binary mask of selected contours \ntop_x, bottom_x, center_v_x = pcv.x_axis_pseudolandmarks(img=img, obj=obj, mask=mask)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"top_y, bottom_y, center_v_y = pcv.y_axis_pseudolandmarks(img=img, obj=obj, mask=mask)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# The print_results function will take the measurements stored when running any (or all) of these functions, format, \n# and print an output text file for data analysis. The Outputs class stores data whenever any of the following functions\n# are ran: analyze_bound_horizontal, analyze_bound_vertical, analyze_color, analyze_nir_intensity, analyze_object, \n# fluor_fvfm, report_size_marker_area, watershed. If no functions have been run, it will print an empty text file \npcv.print_results(filename='vis_tutorial_results.txt')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To view and/or download the text file output (saved in JSON format)...\n1) To see the text file with data that got saved out, click “File” tab in top left corner.\n2) Click “Open…”\n3) Open the file named “vis_tutorial_results.txt”\n\nCheck out documentation on how to [convert JSON](https://plantcv.readthedocs.io/en/latest/tools/#convert-output-json-data-files-to-csv-tables) format output into table formatted output. Depending on the analysis steps a PlantCV user may have two CSV files (single value traits and multivalue traits). \n"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}